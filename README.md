# msra-project
This is a project using In-Context Learning to optimize the prompt.

## Paper List

### In-Context Learning
1. [Active Example Selection for In-Context Learning](https://arxiv.org/abs/2211.04486)
   * Submitted on 8 Nov 2022
2. [Structured Prompting: Scaling In-Context Learning to 1,000 Examples](https://arxiv.org/abs/2212.06713)
   * Submitted on 13 Dec 2022
3. [Pre-Training to Learn in Context](https://arxiv.org/abs/2305.09137)
   * Submitted on 16 May 2023

### Prompt Tuning/Engineering
1. [Extensible Prompts for Language Models on Zero-shot Language Style Customization](https://arxiv.org/abs/2212.00616)
   * Submitted on 1 Dec 2022, last revised 30 Nov 2023
2. [Dynamic Prompting: A Unified Framework for Prompt Tuning](https://arxiv.org/abs/2303.02909)
   * Submitted on 6 Mar 2023, last revised 27 May 2023
3. [When Do Prompting and Prefix-Tuning Work? A Theory of Capabilities and Limitations](https://arxiv.org/abs/2310.19698)
   * Submitted on 30 Oct 2023

### Use ICL to optimize prompt
1. [How Does In-Context Learning Help Prompt Tuning?](https://arxiv.org/abs/2302.11521)
   * Submitted on 22 Feb 2023
2. [Efficient Prompting via Dynamic In-Context Learning](https://arxiv.org/abs/2305.11170)
   * Submitted on 18 May 2023
3. [PhaseEvo: Towards Unified In-Context Prompt Optimization for Large Language Models](https://arxiv.org/abs/2402.11347)
   * Submitted on 17 Feb 2024 

### LLM as Optimizer
1. [Large Language Models as Optimizers](https://arxiv.org/abs/2309.03409)
   * Submitted on 7 Sep 2023, last revised 7 Dec 2023
2. [Are Large Language Models Good Prompt Optimizers?](https://arxiv.org/abs/2402.02101)
   * Submitted on 3 Feb 2024